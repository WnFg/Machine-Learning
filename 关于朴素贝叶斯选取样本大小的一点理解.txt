由统计学知，如果每个特征需要N个样本，那么对于10个特征则需要N^10个样本。原因是什么？
这是在翻看《机器学习实战》这本书时，关于朴素贝叶斯这一章中提到的，其中的原因是什么？
还有下面说如果特征之间是独立的话，则可以减少到10*N个样本，Why!?

自己的理解：假如有两个特征X,Y,它们是有相关性的，那么当我求p(Y|X=x)的条件概率分布时，
单就X=x这个空间里就需要N个样本，那么总共需要num(X)*N个样本，num(X)代表X样本的取值个数。
如果特征之间相互独立的话，那么p(Y|X=x)=p(Y),也就是只需要N个样本就好了。
